{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What we've learned\n",
    "\n",
    "1. There are patterns with `Weather`, `Mosquitoes`, and `WnvPresent`.\n",
    "2. `LabelEncoder` allows us to get around hundreds of dummy columns.\n",
    "3. Rounding/Estimating location is much better than an exact `Lat & Long`.\n",
    "4. `Weather` is cyclical.\n",
    "\n",
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/test.csv')\n",
    "df_train = pd.read_csv('../data/train.csv')\n",
    "df_weather = pd.read_csv('../data/weather_cleaned.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['Date'] = pd.to_datetime(df_test['Date'])\n",
    "df_test.set_index('Date',inplace=True)\n",
    "\n",
    "df_train['Date'] = pd.to_datetime(df_train['Date'])\n",
    "df_train.set_index('Date',inplace=True)\n",
    "\n",
    "df_weather['Date'] = pd.to_datetime(df_weather['Date'])\n",
    "df_weather.set_index('Date',inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling Weather\n",
    "\n",
    "Since we know that weather is cyclical and that mosquitoes have birth patterns, we want to be able to use rolling means of weather data to help us predict `WnvPresent`. At first we focused on using `7`, `14`, `21`, `28`, but that process didn't produce the best results, and was also extremely tedious.\n",
    "\n",
    "So we wrote a function to randomly select a date for rolling means from 3-30. And we found the hard coded values to be best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_roll(weather_cols):\n",
    "    for w in weather_cols:\n",
    "        days = np.random.choice(range(3,30),1)[0]\n",
    "        df_weather[w+'_roll_'+str(days)] = df_weather[w].rolling(days).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#random_roll(['ResultSpeed','PrecipTotal','DewPoint','WetBulb','StnPressure','SeaLevel','AvgSpeed','Heat','Tmax','Tmin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_weather['ResultSpeed_21'] = df_weather['ResultSpeed'].rolling(21).mean()\n",
    "df_weather['PrecipTotal_15'] = df_weather['PrecipTotal'].rolling(15).sum()\n",
    "df_weather['DewPoint_16'] = df_weather['DewPoint'].rolling(16).mean()\n",
    "df_weather['AvgSpeed_19'] = df_weather['AvgSpeed'].rolling(19).mean()\n",
    "df_weather['Heat_28'] = df_weather['Heat'].rolling(28).mean()\n",
    "df_weather['Tmax_4'] = df_weather['Tmax'].rolling(4).mean()\n",
    "df_weather['Tmin_8'] = df_weather['Tmin'].rolling(8).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round Lat & Long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['Lat_int'] = df_train['Latitude'].apply(int)\n",
    "df_train['Long_int'] = df_train['Longitude'].apply(int)\n",
    "df_test['Lat_int'] = df_test['Latitude'].apply(int)\n",
    "df_test['Long_int'] = df_test['Longitude'].apply(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.merge(left=df_train,right=df_weather,on='Date')\n",
    "df_test = pd.merge(left=df_test,right=df_weather,on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.drop(['Station', 'Tmax', 'Tmin', 'Tavg', 'DewPoint', 'WetBulb', 'Heat',\n",
    "       'Cool', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed',\n",
    "       'ResultDir', 'AvgSpeed','Address', 'Block','Latitude','Longitude',\n",
    "         'AddressNumberAndStreet','AddressAccuracy','NumMosquitos'],axis=1,inplace=True)\n",
    "\n",
    "df_test.drop(['Id','Station', 'Tmax', 'Tmin', 'Tavg', 'DewPoint', 'WetBulb', 'Heat',\n",
    "       'Cool', 'PrecipTotal', 'StnPressure', 'SeaLevel', 'ResultSpeed',\n",
    "       'ResultDir', 'AvgSpeed','Address', 'Block','Latitude','Longitude',\n",
    "         'AddressNumberAndStreet','AddressAccuracy'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Species\n",
    "\n",
    "At first we used `LabelEncoder` for `Species` but with further tuning and scoring, we found that using a binary classification for `Species` that's based on having a correlated value to `WnvPresent` is better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_wn = ['CULEX ERRATICUS','CULEX SALINARIUS','CULEX TARSALIS','CULEX TERRITANS']\n",
    "yes_wn = ['CULEX PIPIENS/RESTUANS', 'CULEX RESTUANS', 'CULEX PIPIENS']\n",
    "\n",
    "df_train['Species'] = df_train['Species'].map(lambda x: 1 if x in yes_wn else 0)\n",
    "df_test['Species'] = df_test['Species'].map(lambda x: 1 if x in yes_wn else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# Convert categorical data to numbers\n",
    "lbl = preprocessing.LabelEncoder()\n",
    "# lbl.fit(list(df['Species'].values) + list(df1['Species'].values))\n",
    "# df['Species'] = lbl.transform(df['Species'].values)\n",
    "# df1['Species'] = lbl.transform(df1['Species'].values)\n",
    "\n",
    "lbl.fit(list(df_train['Street'].values) + list(df_test['Street'].values))\n",
    "df_train['Street'] = lbl.transform(df_train['Street'].values)\n",
    "df_test['Street'] = lbl.transform(df_test['Street'].values)\n",
    "\n",
    "lbl.fit(list(df_train['Trap'].values) + list(df_test['Trap'].values))\n",
    "df_train['Trap'] = lbl.transform(df_train['Trap'].values)\n",
    "df_test['Trap'] = lbl.transform(df_test['Trap'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Drops\n",
    "\n",
    "Through numerous iterations, feature comparisons, testing, and tuning, we dropped certain values right before modeling to obtain the best results. However, our best models kept all of our final features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.drop([''],axis=1,inplace=True)\n",
    "#df_test.drop([''],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model RandomForestClassifier\n",
    "\n",
    "This is a tree, but each split is made on a random feature, ensuring that the model isn't biased to only picking/fitting based on the strongest feature. We found little to no gain after hypertuning, thus we're sticking to 1000 trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.drop('WnvPresent',axis=1)\n",
    "y = df_train['WnvPresent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "rf = RandomForestClassifier(n_estimators=1000,n_jobs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss = ss.fit_transform(X)\n",
    "X_test_ss = ss.transform(df_test)\n",
    "\n",
    "rf.fit(X_train_ss,y);\n",
    "\n",
    "test_preds = rf.predict_proba(X_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit = pd.read_csv('../data/sampleSubmission.csv')\n",
    "submit['WnvPresent'] = 1-test_preds\n",
    "submit.to_csv('../kaggle/random_roll_random_forest.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At times, we get very high scores between 60-67% or very low scores between 31-35%. In the later case, we do `1-preds` so that we can get the highest score. If we're very 'bad' at predicting `WnvPresent`, then we can simple flip out predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model as a pickle\n",
    "with open('../assets/random_roll_random_forest.pkl', 'wb+') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Species</td>\n",
       "      <td>0.008183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Street</td>\n",
       "      <td>0.343346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Trap</td>\n",
       "      <td>0.389918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lat_int</td>\n",
       "      <td>0.014845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Long_int</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ResultSpeed_21</td>\n",
       "      <td>0.044472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PrecipTotal_15</td>\n",
       "      <td>0.030347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>DewPoint_16</td>\n",
       "      <td>0.047255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AvgSpeed_19</td>\n",
       "      <td>0.034524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Heat_28</td>\n",
       "      <td>0.030297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Tmax_4</td>\n",
       "      <td>0.029762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Tmin_8</td>\n",
       "      <td>0.027050</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Feature    Weight\n",
       "0          Species  0.008183\n",
       "1           Street  0.343346\n",
       "2             Trap  0.389918\n",
       "3          Lat_int  0.014845\n",
       "4         Long_int  0.000000\n",
       "5   ResultSpeed_21  0.044472\n",
       "6   PrecipTotal_15  0.030347\n",
       "7      DewPoint_16  0.047255\n",
       "8      AvgSpeed_19  0.034524\n",
       "9          Heat_28  0.030297\n",
       "10          Tmax_4  0.029762\n",
       "11          Tmin_8  0.027050"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame({'Feature':X.columns,'Weight':rf.feature_importances_})\n",
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score 0.71717\n",
    "\n",
    "This is our highest score yet. And on the full Kaggle dataset, we score `0.68223`! But we want to have over 70% on the full kaggle dataset. So let's do that!\n",
    "\n",
    "# PCA - Principal Component Analysis\n",
    "This allows us to extract features without dropping features. We believe we have the best selection of features, and to further reduce that, we're going to do feature extraction.\n",
    "\n",
    "**Feature Extraction**\n",
    "- In feature extraction, we take our existing features and combine them together in a particular way. We can then drop some of these \"new\" variables, but the variables we keep are still a combination of the old variables!\n",
    "- This allows us to still reduce the number of features in our model **but** we can keep all of the most important pieces of the original features!\n",
    "\n",
    "After multiple iterations, we found 5 components (the number of linear combinations with increased explained variance with each added component) to be the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=3,n_components=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ss = ss.fit_transform(X)\n",
    "X_test_ss = ss.transform(df_test)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train_ss)\n",
    "X_test_pca = pca.transform(X_test_ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our explained variance:\n",
      " [0.37717204 0.48816358 0.59423562 0.68681201 0.77662438]\n"
     ]
    }
   ],
   "source": [
    "print('Our explained variance:\\n',np.cumsum(pca.explained_variance_ratio_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that these 5 components explains nearly 80% of the variance within our dataset. There was little to no benefit when going to 6 components which is closer to 85%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_pca,y);\n",
    "test_preds = rf.predict_proba(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model as a pickle\n",
    "with open('../assets/random_roll_random_forest_pca_5.pkl', 'wb+') as f:\n",
    "    pickle.dump(rf, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "submit['WnvPresent'] = 1-test_preds\n",
    "submit.to_csv('../kaggle/random_roll_random_forest_pca_5.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score 0.71974\n",
    "\n",
    "This is our highest score yet. And on the full Kaggle dataset, we score `0.70150`!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
