{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beating the Benchmark\n",
    "\n",
    "## This notebook took a script from the kaggle competition discussion board to better understand  which features produced a signal for predicting West Nile Virus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we import the dependencies for doing some data manipulation and for machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "# Borrowing from https://www.kaggle.com/abhishek/vote-me-up\n",
    "import pandas as pd;\n",
    "import numpy as np;\n",
    "from sklearn.ensemble import RandomForestClassifier;\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier;\n",
    "from sklearn.ensemble import BaggingRegressor, BaggingClassifier;\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will load in the different data sets we are using to create a way to predict West Nile Virus.\n",
    "\n",
    "Here is a description of each file and how it is used:\n",
    "1. **train.csv**: This is a spreadsheet with various values that we will use to train our machine learning model so that we can predict the incidence of West Nile Virus from unseen data.\n",
    "2. **test.csv**: This spreadsheet is similar to the train spreadsheet with some columns missing. The values from this spreadsheet are used to create our predictions.\n",
    "3. **sample.csv**: We are using this to submit our kaggle submissions. We will overwrite the \"WnvPresent\" column with our predictions.\n",
    "4. **weather.csv**: This spreadsheet is utilized alongside our train.csv to help train our machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv')\n",
    "test = pd.read_csv('../input/test.csv')\n",
    "sample = pd.read_csv('../input/sampleSubmission.csv')\n",
    "weather = pd.read_csv('../input/weather.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is grabbing our target values for when we train our machine learning model. This will be the true values that we will compare our predictions against as we train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get labels\n",
    "labels = train.WnvPresent.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we are going to clean up our data by:\n",
    "1. Dropping columns that do not seem helpful for building our predictions\n",
    "2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not using codesum for this benchmark\n",
    "weather = weather.drop('CodeSum', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split station 1 and 2 and join horizontally\n",
    "weather_stn1 = weather[weather['Station']==1]\n",
    "weather_stn2 = weather[weather['Station']==2]\n",
    "weather_stn1 = weather_stn1.drop('Station', axis=1)\n",
    "weather_stn2 = weather_stn2.drop('Station', axis=1)\n",
    "weather = weather_stn1.merge(weather_stn2, on='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace some missing values and T with -1\n",
    "weather = weather.replace('M', -1)\n",
    "weather = weather.replace('-', -1)\n",
    "weather = weather.replace('T', -1)\n",
    "weather = weather.replace(' T', -1)\n",
    "weather = weather.replace('  T', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to extract month and day from dataset\n",
    "# You can also use parse_dates of Pandas.\n",
    "def create_month(x):\n",
    "    return x.split('-')[1]\n",
    "\n",
    "def create_day(x):\n",
    "    return x.split('-')[2]\n",
    "\n",
    "train['month'] = train.Date.apply(create_month)\n",
    "train['day'] = train.Date.apply(create_day)\n",
    "test['month'] = test.Date.apply(create_month)\n",
    "test['day'] = test.Date.apply(create_day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add integer latitude/longitude columns\n",
    "train['Lat_int'] = train.Latitude.apply(int)\n",
    "train['Long_int'] = train.Longitude.apply(int)\n",
    "test['Lat_int'] = test.Latitude.apply(int)\n",
    "test['Long_int'] = test.Longitude.apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop address columns\n",
    "\n",
    "train = train.drop(['Address', 'AddressNumberAndStreet'], axis = 1)\n",
    "test = test.drop(['Id', 'Address', 'AddressNumberAndStreet'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with weather data\n",
    "train = train.merge(weather, on='Date')\n",
    "test = test.merge(weather, on='Date')\n",
    "train = train.drop(['Date'], axis = 1)\n",
    "test = test.drop(['Date'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numbers\n",
    "lbl = LabelEncoder()\n",
    "lbl.fit(list(train['Species'].values) + list(test['Species'].values))\n",
    "train['Species'] = lbl.transform(train['Species'].values)\n",
    "test['Species'] = lbl.transform(test['Species'].values)\n",
    "\n",
    "lbl.fit(list(train['Street'].values) + list(test['Street'].values))\n",
    "train['Street'] = lbl.transform(train['Street'].values)\n",
    "test['Street'] = lbl.transform(test['Street'].values)\n",
    "\n",
    "lbl.fit(list(train['Trap'].values) + list(test['Trap'].values))\n",
    "train['Trap'] = lbl.transform(train['Trap'].values)\n",
    "test['Trap'] = lbl.transform(test['Trap'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with -1s\n",
    "train = train.loc[:,(train != -1).any(axis=0)];\n",
    "test = test.loc[:,(test != -1).any(axis=0)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=[\"WnvPresent\"])\n",
    "y = train[\"WnvPresent\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "# Scale our data\n",
    "ss = StandardScaler()\n",
    "X_train_scaled = ss.fit_transform(X_train)\n",
    "X_test_scaled = ss.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# grid = ParameterGrid({\"max_samples\": [0.5, 1.0],\n",
    "#                           \"max_features\": [0.5, 1.0],\n",
    "#                           \"bootstrap\": [True, False],\n",
    "#                           \"bootstrap_features\": [True, False]})\n",
    "\n",
    "# for base_estimator in [None,DecisionTreeClassifier(), RandomForestClassifier()]:\n",
    "#     for params in grid:\n",
    "#         br = BaggingClassifier(base_estimator=base_estimator,\n",
    "#                          **params).fit(X_train_scaled, y_train)\n",
    "#         preds = br.predict(X_train_scaled)\n",
    "#         test_preds = br.predict(X_test_scaled)\n",
    "#         print(f\"Scores for {str(base_estimator)} and {params}\")        \n",
    "#         print(f\"RocAuc for train data: {roc_auc_score(y_train, preds)}\")\n",
    "#         print(f\"RocAuc for test data: {roc_auc_score(y_test, test_preds)}\")\n",
    "#         [print() for _ in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = train.drop(columns=[\"NumMosquitos\"])\n",
    "# y = train[\"NumMosquitos\"]\n",
    "\n",
    "# test_preds = BaggingRegressor(\n",
    "#     base_estimator=DecisionTreeRegressor(),\n",
    "#     bootstrap=False,\n",
    "#     bootstrap_features=False,\n",
    "#     max_features=1.0,\n",
    "#     max_samples=1.0).fit(X, y).predict(test)\n",
    "\n",
    "# test[\"NumMosquitos\"] = test_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=4)\n",
    "\n",
    "# pca_train = pca.fit_transform(train)\n",
    "# pca_test = pca.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ensemble' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-791727cbca78>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Random Forest Classifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensemble\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpca_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# create predictions and submission file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ensemble' is not defined"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier \n",
    "clf = ensemble.RandomForestClassifier(n_estimators=1000)\n",
    "clf.fit(pca_train, labels)\n",
    "\n",
    "# create predictions and submission file\n",
    "predictions = clf.predict_proba(pca_test)[:,1]\n",
    "sample['WnvPresent'] = predictions\n",
    "file_name = 'beat_the_benchmark.csv'\n",
    "sample.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how the features were weighted by the RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Feature':test.columns,'Weight':sorted(clf.feature_importances_, reverse=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Kaggle\n",
    "\n",
    "I am using the [kaggle CLI](http://wiki.fast.ai/index.php/Kaggle_CLI) to submit my predictions. Once the submission has been successfully submitted, the browser will open the kaggle leaderboard page so I can check the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import subprocess, webbrowser\n",
    "# result = subprocess.check_output(f'kaggle competitions submit -f {file_name} -m \"uploading a new set\" predict-west-nile-virus')\n",
    "# webbrowser.open(\"https://www.kaggle.com/c/predict-west-nile-virus/leaderboard\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
